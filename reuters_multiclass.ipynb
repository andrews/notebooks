{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faf3e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixes some matplotlib issues i was having that was killing the kernel\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e609fe75",
   "metadata": {},
   "source": [
    "# Reuters Dataset\n",
    "Multiclass classification example\n",
    "\n",
    "Youâ€™ll work with the Reuters dataset, a set of short newswires and their topics, published by Reuters in 1986. There are 46 topics, with some represented more than others (unbalanced dataset), but each topic has at least 10 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0ac8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import tensorflow as tf\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d338ed63",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0d4c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2110848/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000) # 10k most frequently occurring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2723aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e00de32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593a74b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again words have been mapped to integers. samples are sequences of integers. word indices\n",
    "# train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84fed2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# topics\n",
    "print(max(train_labels))\n",
    "print(min(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f56d2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 3159,\n",
       "         4: 1949,\n",
       "         16: 444,\n",
       "         19: 549,\n",
       "         8: 139,\n",
       "         21: 100,\n",
       "         11: 390,\n",
       "         1: 432,\n",
       "         13: 172,\n",
       "         20: 269,\n",
       "         18: 66,\n",
       "         25: 92,\n",
       "         35: 10,\n",
       "         9: 101,\n",
       "         38: 19,\n",
       "         10: 124,\n",
       "         28: 48,\n",
       "         2: 74,\n",
       "         6: 48,\n",
       "         12: 49,\n",
       "         7: 16,\n",
       "         30: 45,\n",
       "         34: 50,\n",
       "         15: 20,\n",
       "         14: 26,\n",
       "         32: 32,\n",
       "         41: 30,\n",
       "         40: 36,\n",
       "         45: 18,\n",
       "         23: 41,\n",
       "         42: 13,\n",
       "         26: 24,\n",
       "         24: 62,\n",
       "         37: 19,\n",
       "         27: 15,\n",
       "         31: 39,\n",
       "         39: 24,\n",
       "         0: 55,\n",
       "         22: 15,\n",
       "         33: 11,\n",
       "         36: 49,\n",
       "         17: 39,\n",
       "         43: 21,\n",
       "         29: 19,\n",
       "         44: 12,\n",
       "         5: 17})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts per topic\n",
    "collections.Counter(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9dbe4",
   "metadata": {},
   "source": [
    "### Preparing data\n",
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc369070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cddf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. # note the .\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69879a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08cc055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to one-hot encode the labels\n",
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "# this look the same as above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5766d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463d9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built in way to do this in keras. probably faster too\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76851f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18633220",
   "metadata": {},
   "source": [
    "### Building the network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
